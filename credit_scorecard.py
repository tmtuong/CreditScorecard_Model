# -*- coding: utf-8 -*-
"""Credit_Scorecard.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17-CZ8uNtcn0EodD2Y4SsirSEA8CCuglh
"""

import pandas as pd
import seaborn as sns
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, roc_curve, auc, precision_recall_curve
from scipy import stats


"""#Xử lý missing"""

def fill_missing(df, y_col):
  columns_num = df.select_dtypes(['float', 'int']).columns
  df[columns_num] = df[columns_num].apply(lambda x: x.fillna(x.mean()), axis=0)

  columns_obj = df.select_dtypes(['object']).columns
  df[columns_obj] = df[columns_obj].apply(lambda x: x.fillna('Missing'), axis=0)

  x_col = df.columns.drop(y_col)
  return df, x_col


"""#Tính WOE, IV"""

def woe_point(x):
  point = 0
  for k in range(0,len(x)-2):
    if (x[k+1] > x[k]) and (x[k+1] > x[k+2]):
      point +=1
    elif (x[k+1] < x[k]) and (x[k+1]<x[k+2]):
      point +=1
  return point

def get_iv(data, col, bin, qcut = None):
    MAX_VAL = 999999999
    MIN_VAL = -MAX_VAL
    coltype = data[col].dtype

    if coltype in ['float', 'int']:
      if qcut is None:
        try:
          bins, thres = pd.qcut(data[col], q = bin, retbins=True)
          # Thay thế threshold đầu và cuối của thres
          thres[0] = MIN_VAL
          thres[-1] = MAX_VAL
          bins, thres = pd.cut(data[col], bins=thres, retbins=True)
          data['bins'] = bins
        except:
          # print('n_bins must be lower to bin interval is valid!')
          pass
      else:
        bins, thres = pd.cut(data[col], bins=qcut, retbins=True)
        data['bins'] = bins
    elif coltype == 'object':
      data['bins'] = data[col]

    dfgb = data.groupby(['bins']).agg({col:'count','BAD':'sum'}).reset_index()

    dfgb.columns = ['bins','Obs','#Bad']
    dfgb['#Good'] = dfgb['Obs'] - dfgb['#Bad']


    dfgb['Good/Bad'] = dfgb['#Good']/dfgb['#Bad']
    dfgb['%Bad'] = dfgb['#Bad']/dfgb['#Bad'].sum()
    dfgb['%Good'] = dfgb['#Good']/dfgb['#Good'].sum()
    dfgb['WOE'] = np.log(dfgb['%Good']/dfgb['%Bad'])
    dfgb['IV'] = (dfgb['%Good']-dfgb['%Bad'])*dfgb['WOE']
    dfgb['COLUMN'] = col
    IV = dfgb['IV'].sum()
    dfgb.set_index(dfgb['bins'],inplace =True)
    # print('Information Value of {} column: {}'.format(col, IV))
    return dfgb, IV

def _rank_IV(iv):
  if iv <= 0.02:
    return 'Useless'
  elif iv <= 0.1:
    return 'Weak'
  elif iv <= 0.3:
    return 'Medium'
  elif iv <= 0.5:
    return 'Strong'
  else:
    return 'Suspicious'

def iv_score(df,x_col,nomial_col):
  WOE_dict = {}
  iv= None
  df_woe = pd.DataFrame()
  for i in x_col:
    if i in nomial_col:
      df_woe, iv = get_iv(df, i, 5, [-999,2,999])
      print(f'IV of {i}: {iv}')

    elif df[i].dtypes in ['float', 'int']:
      point_dict = {}
      for n in range(3,11):
        try:
          df_woe, iv = get_iv(df, i, n)
          point_dict[n] = woe_point(list(df_woe['WOE']))
        except:
          point_dict[n] = -1
          continue
      max_key = min(sorted(point_dict.items(), key=lambda item: (-item[1], item[0])))[0]
      df_woe, iv = get_iv(df, i, max_key)
      print(f'IV of {i}: {iv}')

    elif df[i].dtypes == 'object':
      df_woe, iv = get_iv(df, i, 5)
      print(f'IV of {i}: {iv}')

    WOE_dict[i] = {'table':df_woe, 'IV':iv}

  columns = []
  IVs = []
  for col in x_col:
    if col != 'BAD':
      columns.append(col)
      IVs.append(WOE_dict[col]['IV'])
  df_WOE = pd.DataFrame({'column': columns, 'IV': IVs})

  df_WOE['rank']=df_WOE['IV'].apply(lambda x: _rank_IV(x))
  df_WOE.sort_values('IV', ascending=False, inplace=True)
  return df_WOE, WOE_dict, columns



def ml_input(WOE_dict,df):
  for col in WOE_dict.keys():
    try:
      key = list(WOE_dict[col]['table']['WOE'].index)
      woe = list(WOE_dict[col]['table']['WOE'])
      d = dict(zip(key, woe))
      col_woe = col+'_WOE'
      df[col_woe] = df[col].map(d)
    except:
      pass
  X = df.filter(like='_WOE', axis = 1)
  y = df['BAD']

  return df, X,y

"""# Logistic Regression"""



def build_model(X_train, X_test, y_train, y_test, id_train, id_test):

  logit_model = LogisticRegression(solver = 'lbfgs', max_iter=1000, fit_intercept=True, tol=0.0001, C=1, penalty='l2')
  logit_model.fit(X_train, y_train)

  y_pred_train = logit_model.predict(X_train)
  acc_train = accuracy_score(y_pred_train, y_train)
  y_pred_test = logit_model.predict(X_test)
  acc_test = accuracy_score(y_pred_test, y_test)

  y_pred_prob_test = logit_model.predict_proba(X_test)[:, 1]
  fpr, tpr, thres_roc = roc_curve(y_test, y_pred_prob_test)
  roc_auc = auc(fpr, tpr)

  precision, recall, thres_pre = precision_recall_curve(y_test, y_pred_prob_test)
  alpha = logit_model.intercept_[0]
  coef_ = logit_model.coef_[0]
  return alpha,coef_, fpr, tpr, thres_roc, roc_auc, precision, recall, thres_pre,y_pred_prob_test, acc_test, acc_train


def _plot_roc_curve(fpr, tpr, thres, auc):
    fig, ax = plt.subplots(figsize=(10, 8))
    ax.plot(fpr, tpr, 'b-', color='darkorange', lw=2, linestyle='--', label='ROC curve (area = %0.2f)' % auc)
    ax.plot([0, 1], [0, 1], '--')
    ax.axis([0, 1, 0, 1])
    ax.set_xlabel('False Positive Rate')
    ax.set_ylabel('True Positive Rate')
    ax.legend(loc='lower right')
    ax.set_title('ROC Curve')
    
    return ax, fig


def _plot_prec_rec_curve(prec, rec, thres):
    fig, ax = plt.subplots(figsize=(10, 8))
    ax.plot(thres, prec[:-1], 'b--', label='Precision')
    ax.plot(thres, rec[:-1], 'g-', label='Recall')
    ax.set_xlabel('Threshold')
    ax.set_ylabel('Probability')
    ax.set_title('Precision vs Recall Curve')
    ax.legend()
    
    return ax, fig


"""#Kiểm định"""

def _KM(y_pred, n_bins,y_test):
  _, thresholds = pd.qcut(y_pred, q=n_bins, retbins=True)
  cmd_BAD = []
  cmd_GOOD = []
  BAD_id = set(np.where(y_test == 0)[0])
  GOOD_id = set(np.where(y_test == 1)[0])
  total_BAD = len(BAD_id)
  total_GOOD = len(GOOD_id)
  for thres in thresholds:
    pred_id = set(np.where(y_pred <= thres)[0])
    # Đếm % số lượng hồ sơ BAD có xác suất dự báo nhỏ hơn hoặc bằng thres
    per_BAD = len(pred_id.intersection(BAD_id))/total_BAD
    cmd_BAD.append(per_BAD)
    # Đếm % số lượng hồ sơ GOOD có xác suất dự báo nhỏ hơn hoặc bằng thres
    per_GOOD = len(pred_id.intersection(GOOD_id))/total_GOOD
    cmd_GOOD.append(per_GOOD)
  cmd_BAD = np.array(cmd_BAD)
  cmd_GOOD = np.array(cmd_GOOD)
  return cmd_BAD, cmd_GOOD, thresholds


def _plot_KM(cmd_BAD, cmd_GOOD, thresholds):
    fig, ax = plt.subplots(figsize=(10, 8))
    ax.plot(thresholds, cmd_BAD, 'y-', label='BAD')
    ax.plot(thresholds, cmd_GOOD, 'g-', label='GOOD')
    ax.plot(thresholds, cmd_BAD - cmd_GOOD, 'b--', label='DIFF')
    ax.set_xlabel('% observation')
    ax.set_ylabel('% total GOOD/BAD')
    ax.set_title('Kolmogorov-Smirnov Curve')
    ax.legend()
    
    return ax, fig



"""#Credit Score"""

def _CreditScore(beta, alpha, woe, n = 12, odds = 1/4, pdo = -50, thres_score = 600):
  factor = pdo/np.log(2)
  offset = thres_score - factor*np.log(odds)
  score = (beta*woe+alpha/n)*factor+offset/n
  return score


def get_beta(X_train,alpha,coef_,columns,WOE_dict):
  betas_dict = dict(zip(list(X_train.columns), coef_))

  cols = []
  features = []
  woes = []
  betas = []
  scores = []

  for col in columns:
    for feature, woe in WOE_dict[col]['table']['WOE'].to_frame().iterrows():
        cols.append(col)
        # Add feature
        feature = str(feature)
        features.append(feature)
        # Add woe
        woe = woe.values[0]
        woes.append(woe)
        # Add beta
        col_woe = col+'_WOE'
        beta = betas_dict[col_woe]
        betas.append(beta)
        # Add score
        score = _CreditScore(beta = beta, alpha = alpha, woe = woe, n = 12)
        scores.append(score)

  df_WOE = pd.DataFrame({'Columns': cols, 'Features': features, 'WOE': woes, 'Betas':betas, 'Scores':scores})

  return df_WOE


# # Giả sử một hồ sơ ndf_WOE = get_beta(X_train,logit_model,columns)
# test_obs = df[columns].iloc[0:1, :]
# test_obs

def _search_score(obs, col,WOE_dict,df_WOE):
  feature = [str(inter) for inter in list(WOE_dict[col]['table'].index) if obs[col].values[0] in inter][0]
  score = df_WOE[(df_WOE['Columns'] == col) & (df_WOE['Features'] == feature)]['Scores'].values[0]
  return score

# # Tính điểm cho trường 'LOAN' của bộ hồ sơ test
# score = _search_score(test_obs, 'LOAN')
# score

def _total_score(obs, columns,WOE_dict,df_WOE):
  scores = dict()
  for col in columns:
    scores[col] = _search_score(obs, col,WOE_dict,df_WOE)
  total_score = sum(scores.values())
  return scores, total_score

# scores, total_score = _total_score(test_obs)
# print('score for each fields: \n', scores)
# print('final total score: ', total_score)

def cal_score(df,columns,WOE_dict,df_WOE):
  total_scores = []
  for i in np.arange(df[columns].shape[0]):
    obs = df[columns].iloc[i:(i+1), :]
    _, score = _total_score(obs,columns,WOE_dict,df_WOE)
    total_scores.append(score)
  df['Score'] = total_scores

  return df

# df = cal_score(df)

def plot_score(df):
    fig, axes = plt.subplots(1, 2, figsize=(16, 4))
    
    sns.distplot(df['Score'], ax=axes[0])
    axes[0].set_title('Distribution Score of Total data')
    
    sns.distplot(df[df['BAD']==1]['Score'], label='Default', ax=axes[1])
    sns.distplot(df[df['BAD']==0]['Score'], label='Non-Default',
                 kde_kws={"color": "r"},
                 hist_kws={"color": "g", "alpha":0.5}, ax=axes[1])
    
    axes[1].legend(loc='lower right')
    axes[1].set_title('Distribution Score in Default vs Non-Default')
    
    return axes, fig

# plot_score(df)

def score_segment(df):
  df['credit_score_bin'], thres = pd.cut(df['Score'], bins=[0,350,500,650,800,1000], retbins=True)
  seg = df.groupby(['credit_score_bin']).agg({'BAD':'sum','Score':'count'}).reset_index()
  seg['prob'] = seg['BAD']/seg['Score']
  total_people = seg['Score'].sum()

  seg['Score Range'] = [str(i) + ' - ' +str(j) for i,j in zip(thres[:-1], thres[1:])]
  seg['% of people'] = [str(round(i/j*100,2)) + '%' for i, j in zip(seg['Score'], [total_people]*len(seg))]
  seg['% Fraud'] = [str(round(i*100,2)) + '%' for i in seg['prob']]
  seg['Rating'] = ['Very Poor','Poor','Fair','Good','Very Good']
  scorecard = seg[['Score Range','Rating','% of people','% Fraud']]
  return scorecard

# score_segment(df)